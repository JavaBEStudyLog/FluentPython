# CHAPTER 4 유니코드 텍스트와 바이트

파이썬 3부터는 인간이 사용하는 텍스트 문자열과 기계가 사용하는 원시 바이트 시퀀스를 엄격히 구분하기 시작함

**<이번 장에서 다룰 주요 내용>**

- 문자, 코드 포인트, 바이트 표현
- 이진 시퀀스의 고유한 특징 : bytes, bytearray, memoryview
- 전체 유니코드 및 레거시 문자셋에 대한 코덱
- 인코딩 에러 방지 및 처리
- 텍스트 파일을 다룰 때의 모범 사례
- 기본 인코딩 및 표준 입출력 문제
- 정규화를 이용한 안전한 유니코드 텍스트 비교
- 정규화, 케이스 폴딩, 발음 구별 기호 강제 제거를 위한 유틸리티 함수
- locale과 PyUCA 라이브러리를 이용한 유니코드 텍스트의 적절한 정렬
- 유니코드 데이터베이스 안의 문자 메타데이터
- str과 bytes를 다루는 이중 모드 API

## 4.1 이번 장의 변경 사항

- 4.9.1절 '이름으로 문자 찾기'

## 4.2 문자 문제

'문자열' 이란? 문자의 열  
그렇다면 '문자'란 무엇인가? > '문자'를 가장 잘 정의한 것은 유니코드 문자  
유니코드 표준은 문자의 단위 원소와 특정 바이트 표현을 명확히 구분함

- 문자의 단위 원소 (코드 포인트)는 10진수 ~ 1,114,111까지의 숫자
- 유니코드 표준에서는 'U+' 접두사를 붙여 4자링세ㅓ 6자리 사이의 16진수로 표현
- 문자를 표현하는 실제 바이트는 사용하는 인코딩에 따라 달라짐
- 인코딩 : 코드 포인트 > 바이트 시퀀스 변환 알고리즘

**코드 포인트 > 바이트 : 인코딩**  
**바이트 > 코드 포인트 : 디코딩**

#### ✅ 파이썬 2의 str / 파이썬 3의 변화

- 파이썬 2의 str
  - 문자열이자 동시에 바이트열
  - 문자(텍스트)와 바이트(이진 데이터)의 경계가 모호해서 텍스트 인코딩 문제와 버그가 자주 발생
- 파이썬 3의 변화 > 구분을 시작함
  - str : 유니코드 문자열
    - 텍스트 처리에 사용
    - 파이썬 2의 unicode 형과 상당히 비슷
    - `"안녕하세요" , "Hello"`
  - bytes : 불변 이진 시퀀스
    - 네트워크, 파일 등 이진 데이터 처리에 사용
    - `b"Hello`
  - bytearray : 가변 이진 시퀀스
    - 네트워크, 파일 등 이진 데이터 처리에 사용 + 수정이 가능!
    - `bytearray(b"Hello")`

> 이진 데이터란?  
> 0과 1로만 이루어진 데이터 > 컴퓨터가 이해할 수 있는 가장 기본적인 데이터

## 4.3 바이트 기본 지식

- bytes와 bytearray의 각 항목은 0 ~ 255 사이의 정수
- 파이썬 2의 str처럼 한 문자로 구성된 문자열과는 다름
- 이진 시퀀스를 슬라이싱하면 언제나 똑같은 자료형의 이진 시퀀스가 만들어짐
  - bytes > bytes / bytearray > bytearray
  - 슬라이스 길이가 1일때도 마찬가지

```python
# <bytes>
b = b"hello"
print(type(b))         # <class 'bytes'>
print(b[0])            # 104  ← 정수 (ASCII 코드 h)

# 슬라이싱
print(b[0:1])          # b'h'
print(type(b[0:1]))    # <class 'bytes'>

# <bytearray>
ba = bytearray(b"hello")
print(type(ba))            # <class 'bytearray'>
print(ba[1])               # 101

# 슬라이싱
print(ba[1:2])             # bytearray(b'e')
print(type(ba[1:2]))       # <class 'bytearray'>
```

**파이썬 2에서는 슬라이스든 단일 인덱스든 항상 문자열이 나옴**  
파이썬 3에서는 인덱싱 > 정수 (0 ~ 255) / 슬라이싱 > 같은 타입의 객체가 나옴

> str은 인덱싱도, 슬라이싱 결과도 모두 "문자열"  
> 그 외 모든 파이썬 시퀀스 > 인덱싱은 요소를, 슬라이싱은 해당 시퀀스를 반환!  
> ❓ 왜 str은 예외일까?  
> str은 불변이고, 각 글자도 문자열이기 때문!  
> 예를 들어, 문자열 "hello"는 사실 "h", "e", "l", "l", "0" 라는 1글자짜리 문자열의 나열  
> 인덱싱을 해도 문자열, 슬라이싱을 해도 문자열이 되는 것!!

## 4.4 기본 인코더 / 디코더

- 파이썬 배포본에는 텍스트 > 바이트, 혹은 바이트 > 텍스트 변환하는 100여개의 코덱(인코더/디코더)이 포함되어 있음
- 코덱은 open(), str.encode(), bytes.decode() 등의 함수를 호출할 때 encoding 인수에 전달해 사용할 수 있음

```python
for codec in ['latin_1', 'utf_8', utf_16]:
    print(codec, 'El Niño'.encode(codec), sep='\t')

# latin_1	b'El Ni\xf1o'
# utf_8     b'El Ni\xc3\xb1o'
# utf_16	b'\xff\xfeE\x00l\x00 \x00N\x00i\x00\xf1\x00o\x00'
```

## 4.5 인코딩/디코딩 문제 이해하기

- UnicodeError : 범용 예외
- UnicodeEncodeError : str > 이진 시퀀스 변환 예외
- UnicodeDecodeError : 이진 시퀀스 > str 변환 예외
- SyntaxError : 파이썬 모듈을 로딩할 때 소스 코드가 예기치 않은 방식으로 인코딩되었을 때

### 4.5.1 UnicodeEncodeError의 처리

1. 텍스트를 바이트로 변환할 때 문자가 대상 인코딩에 정의되어 있지 않고
2. 인코딩 메서드나 함수의 errors 인수에 별도의 처리기가 지정되지 않았으면 발생

```python
# 에러 처리 옵션 예시
text = "hello 😊"

# 1. ignore : 문제되는 문자를 건너뜀
encoded = text.encode('ascii', errors='ignore')
print(encoded)  # b'hello '

# 2. replace : 문제되는 문자를 ?로 바꿈
encoded = text.encode('ascii', errors='replace')
print(encoded)  # b'hello ?'

# 3. xmlcharrefreplace : 문제되는 문자를 XML 문자 참조로 바꿈
encoded = text.encode('ascii', errors='xmlcharrefreplace')
print(encoded)  # b'hello &#128522;'
```

### 4.5.2 UnicodeDecodeError의 처리

- 모든 바이트 패턴이 유효한 아스키 문자가 될 수 없음
- 모든 바이트 시퀀스가 유효한 UTF-8이나 UTF-16 문자가 되지는 않음
- 이진 시퀀스를 텍스트로 변환할 때 해당 인코딩의 정당한 문자로 변환할 수 없을 때 발생

```python
text = "안녕하세요"
b = text.encode('utf-8')         # str → bytes

print(b.decode('utf-8'))         # 안녕 : bytes → str ✅ OK
print(b.decode('ascii', errors='replace'))  # �� : bytes → str ❌ → 에러 대신 �로 대체
```

> cp1252, iso8859_1, koi8_r등 여러 레거시 8-비트 인코딩  
> 어떤 바이크 배열이든 디코딩할 수는 있음  
> 그 결과가 **말도 안되는 이상한 글자**일 수도 있음

### 4.5.3 예상과 달리 인코딩된 모듈 로딩 시 발생하는 SyntaxError

파이썬 2.5부터 아스키를, 파이썬 3부터 UTF-8을 소스 코드 기본 인코딩 방식으로 사용

인코딩을 선언하지 않고 UTF-8 이외의 방식으로 인코딩된 .py 모듈을 로딩하면 SyntaxError가 발생함

### 4.5.4 바이트 시퀀스의 인코딩 방식을 알아내는 방법

**없다!** 따라서 인코딩 정보는 반드시 명시되어야 함

### 4.5.5 BOM : 유용한 깨진 문자

BOM(Byte Order Mark)

- 유니코드 텍스트 앞에 붙는 특별한 바이트 시퀀스
- 이 파일이 어떤 방식으로 인코딩되었는지 알려주는 표시

리틀 엔디언 VS 빅 엔디언

- 여러 바이트로 이루어진 데이터를 어느 쪽부터 저장하느냐에 대한 규칙
- 리틀 엔디언 : 뒤쪽부터 큰 쪽 (34 12)
- 빅 엔디언 : 앞쪽부터 큰 쪽 (12 34)

❓ 왜 BOM이 필요할까?

- UTF-16은 2바이트 단위 인코딩 > 바이트 순서가 중요
- 바이트만 보면 누가 누군지 모르기 때문에 BOM을 붙여서 어떤 순서인지 알려줌

## 4.6 텍스트 파일 다루기

**유니코드 샌드위치**

- 입력 시 디코딩 bytes > str
- 내부 100% str
- 출력 시 인코딩 str > bytes

```python
# 인코딩은 지정, 디코딩은 지정하지 않음 > 기본 인코딩 방식을 따름
open('cafe.txt', 'w', encodeing='utf-8').write('café')
# 4

# 플랫폼에 따라 기본 인코딩 방식이 다르기 때문에 글자가 깨지는 문제 발생
open('cafe.txt').read()
# 'cafÃo'
```

### 4.6.1 기본 인코딩 주의하기

..보류..^^..

## 4.7 유니코드 정규화로 제대로 비교하기

유니코드에는 결합 문자가 있어서 문자열 비교가 간단하지 않음  
앞 문자에 연결되는 발음 구별 기호는 인쇄할 때 앞 문자와 하나로 결합되어 출력됨

```python
s1 = 'café'
s2 = 'cafe\N{COMBINING ACUTE ACCENT}'
s1, s2
# ('café', 'café') => 동일한 문자
len(s1), len(s2) # (4, 5) => 코드 포인트가 다름
s1 == s2 # False
```

#### 해결책 : unicodedata.normalize()

같은 문잘르 같은 방식으로 표현되게 표준화하는 과정  
즉, "é"를 'e' + '´' 또는 'é' 중 하나로 통일하는 것!

**정규화 방식 4가지**

1. NFC : Normal Form Composed
   - 코드 포인트를 조합해 가장 짧은 동일 문자열을 생성
   - 가능한 문자들을 합침
   - 'e' + '´' -> 'é'
2. NFD : Normal Form Decomposed
   - 조합된 문자를 기본 문자와 별도의 결합 문자로 분리
   - 가능한 문자들을 쪼갬
   - 'é' -> 'e' + '´'
3. NFKC : Compatibility Composition
   - NFC + 모양 비슷한 문자 통합
   - 의미만 유지 (모양은 통일)
4. NFKD : Compatibility Decomposition
   - NFD + 모양 비슷한 문자 분해
   - 의미 통일
     K : 호환성을 의미 > 정규화의 더 강력한 형태

```python
s = '① café ㍿'

print('원본    :', s)
print('NFC     :', unicodedata.normalize('NFC', s))
print('NFD     :', unicodedata.normalize('NFD', s))
print('NFKC    :', unicodedata.normalize('NFKC', s))
print('NFKD    :', unicodedata.normalize('NFKD', s))

# 출력 결과
원본    : ① café ㍿
NFC     : ① café ㍿
NFD     : ① café ㍿      # 'é'가 분해됨
NFKC    : 1 cafe 株式会社  # 모양 비슷한 문자들을 대체
NFKD    : 1 café 株式会社  # 모양 비슷한 문자 + 분해
```

### 4.7.1 케이스 폴딩

- 대소문자 구분없이 문자열을 비교하거나 처리하기 위해, 모든 문자를 '소문자 비슷한 형태'로 변환하는 것
- 유니코드 문자들의 언어학적, 의미적 일치까지 고려해서 통일
- lower()보다 더 폭넓은 문자 변환을 수행

### 4.7.2 정규화된 텍스트 매칭을 위한 유틸리티 함수

### 4.7.3 극단적인 정규화 : 발음 구별 기호 제거하기

## 4.8 유니코드 텍스트 정렬하기

파이썬은 각 시퀀스의 항목들을 하나하나 비교함으로써 어떠한 자료형의 시퀀스도 정렬할 수 있음  
문자열에서는 코드 포인트를 비교 > 아스키 이외의 문자 사용 시 결과가 달라질 수 있음

- 비아스키 텍스트는 locale.strxfrm() 함수를 이용해서 변환하는 것이 표준
- `locale.setlocale(locale.LC_COLLATE, <지역_언어>)`
- 로케일은 시스템 전역에 영향을 미치므로 사용시 유의 (정렬 방식, 숫자/날짜/통화 포맷 등에 영향을 줄 수 있음)

### 4.8.1 유니코드 대조 알고리즘을 이용한 정렬

유니코드 대조 알고리즘을 순수 파이썬으로만 구현한 PyUCA

- 지역 정보를 고려하지 않음
- 각 문자의 정렬 키를 부여해서 비교
  - 기본 문자 > 악센트 > 대소문자 > 기타 기호 를 순차적으로 고려해서 정렬

```python
pip install pyuca
import pyuca

collator = pyuca.Collator()

words = ['zebra', 'äpfel', 'apple']
sorted_words = sorted(words, key=collator.sort_key)

print(sorted_words)
# ['apple', 'äpfel', 'zebra']
```

#### locale VS PyUCA

| 항목      | locale                        | PyUCA                       |
| --------- | ----------------------------- | --------------------------- |
| 기준      | OS의 로케일 설정              | 유니코드 표준               |
| 작동 방식 | `strxfrm()`으로 정렬 키 생성  | `collator.sort_key()` 사용  |
| 장점      | 시스템 언어 기준 반영         | 일관되고 독립적             |
| 단점      | 시스템 의존적, 전역 상태 변경 | 설치 필요 (외부 라이브러리) |

## 4.9 유니코드 데이터베이스

- 유니코드 표준은 수많은 구조화된 텍스트 파일의 형태로 하나의 완전한 데이터베이스를 제공
- 모든 유니코드 문자에 대한 상세한 정보를 모아놓은 표준 데이터 집합
- 코드 포인트를 문자명으로 매핑하는 테이블
- 각 문자에 대한 메타데이터 및 각 문자가 서로 연관되는 방법

### 4.9.1 이름으로 문자 찾기

unicodedata 모듈에는 문자의 표준 공식 명칭을 반환하는 unicodedata.name() 등 문자 메타데이터를 반환하는 함수들이 존재

```python
import unicodedata

print(unicodedata.name('A'))     # 'LATIN CAPITAL LETTER A'
print(unicodedata.name('♥'))     # 'BLACK HEART SUIT'
```

=> 사용자들이 문자명을 검색할 수 있게 해주는 애플리케이션을 만들 수 있음

### 4.9.2 수를 나타내는 문자

## 4.10 이중 모드 str 및 bytes API

### 4.10.1 정규 표현식에서의 str과 bytes

- bytes형으로 정규 표현식을 만들면 \d \w 같은 패턴들은 아스키 문자만 매칭 (아스키코드 기준)
- str형으로 정규 표현식을 만들면 아스키 문자 외에 유니코드 숫자나 문자도 매칭 (유니코드 기준)

```python
import re

text_str = "1 ² ௧ A 가"  # 아스키 1, 위첨자 2, 타밀 숫자 1, 영문자, 한글

# str 패턴 (유니코드 기준)
str_digit_pattern = re.compile(r"\d")  # 유니코드 숫자 전부
str_word_pattern = re.compile(r"\w")   # 유니코드 문자 전부

print("str 패턴 - \\d:", str_digit_pattern.findall(text_str))
print("str 패턴 - \\w:", str_word_pattern.findall(text_str))

# bytes 패턴 (ASCII 기준)
text_bytes = b"1 A"  # bytes는 유니코드 표현 불가 (오직 ASCII)
bytes_digit_pattern = re.compile(rb"\d")
bytes_word_pattern = re.compile(rb"\w")

print("bytes 패턴 - \\d:", bytes_digit_pattern.findall(text_bytes))
print("bytes 패턴 - \\w:", bytes_word_pattern.findall(text_bytes))

# 실행 결과
str 패턴 - \d: ['1', '²', '௧']
str 패턴 - \w: ['1', '²', '௧', 'A', '가']

bytes 패턴 - \d: [b'1']
bytes 패턴 - \w: [b'1', b'A']
```

=> bytes로 매칭할 수 없는 문자들은 str로 디코딩해서 처리 후 필요하면 다시 bytes로 인코딩해줘야 함

| 패턴 유형 | \d 매칭 대상                                      | \w 매칭 대상                                        |
| --------- | ------------------------------------------------- | --------------------------------------------------- |
| str       | 아스키 숫자 + 위첨자 + 타밀 숫자 등 유니코드 숫자 | 모든 유니코드 문자 (한글, 그리스어, 이모지 등 포함) |
| bytes     | 오직 아스키 숫자 (0~9)                            | 오직 아스키 문자 (a~z, A~Z, \_, 0~9)                |

| 패턴 | 의미              | 포함되는 문자 예시                | str 기준 (유니코드)        | bytes 기준 (ASCII)   |
| ---- | ----------------- | --------------------------------- | -------------------------- | -------------------- |
| \d   | 숫자 (digit)      | 0~9, ², ௧, 등                     | ✅ 모든 유니코드 숫자 포함 | ❌ 0~9만 포함        |
| \w   | 단어 문자 (word)  | 알파벳, 숫자, 밑줄, 한글 등       | ✅ 모든 유니코드 문자 포함 | ❌ a~z, A~Z, 0~9, \_ |
| \s   | 공백 문자 (space) | space, tab, 줄바꿈, 유니코드 공백 | ✅ 유니코드 공백 포함      | ❌ ASCII 공백만 포함 |
